{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elSrFs68qj1a",
        "outputId": "1927c63a-4438-4b13-cec8-0781d7922eba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        sha source_x  \\\n",
            "0  c630ebcdf30652f0422c3ec12a00b50241dc9bd9      CZI   \n",
            "1  53eccda7977a31e3d0f565c884da036b1e85438e      CZI   \n",
            "2  210a892deb1c61577f6fba58505fd65356ce6636      CZI   \n",
            "3  e3b40cc8e0e137c416b4a2273a4dca94ae8178cc      CZI   \n",
            "4  92c2c9839304b4f2bc1276d41b1aa885d8b364fd      CZI   \n",
            "\n",
            "                                               title  \\\n",
            "0  Angiotensin-converting enzyme 2 (ACE2) as a SA...   \n",
            "1  Comparative genetic analysis of the novel coro...   \n",
            "2  Incubation Period and Other Epidemiological Ch...   \n",
            "3  Characteristics of and Public Health Responses...   \n",
            "4       Imaging changes in severe COVID-19 pneumonia   \n",
            "\n",
            "                          doi pmcid pubmed_id   license  \\\n",
            "0  10.1007/s00134-020-05985-9        32125455  cc-by-nc   \n",
            "1   10.1038/s41421-020-0147-1                     cc-by   \n",
            "2          10.3390/jcm9020538                     cc-by   \n",
            "3          10.3390/jcm9020575        32093211     cc-by   \n",
            "4  10.1007/s00134-020-05976-w        32125453  cc-by-nc   \n",
            "\n",
            "                                            abstract publish_time  \\\n",
            "0                                                            2020   \n",
            "1                                                            2020   \n",
            "2  The geographic spread of 2019 novel coronaviru...         2020   \n",
            "3  In December 2019, cases of unidentified pneumo...         2020   \n",
            "4                                                            2020   \n",
            "\n",
            "                                             authors  \\\n",
            "0  Zhang, Haibo; Penninger, Josef M.; Li, Yimin; ...   \n",
            "1  Cao, Yanan; Li, Lin; Feng, Zhimin; Wan, Shengq...   \n",
            "2  Linton, M. Natalie; Kobayashi, Tetsuro; Yang, ...   \n",
            "3                   Deng, Sheng-Qun; Peng, Hong-Juan   \n",
            "4                                         Zhang, Wei   \n",
            "\n",
            "                        journal Microsoft Academic Paper ID WHO #Covidence  \\\n",
            "0            Intensive Care Med                  2002765492          #3252   \n",
            "1                Cell Discovery                  3003430844          #1861   \n",
            "2  Journal of Clinical Medicine                  3006065484          #1043   \n",
            "3                    J Clin Med                   177663115          #1999   \n",
            "4            Intensive Care Med                  3006643024          #3242   \n",
            "\n",
            "  has_full_text  \n",
            "0          True  \n",
            "1          True  \n",
            "2          True  \n",
            "3          True  \n",
            "4         False  \n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "def load_csv_with_error_handling(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        for i, row in enumerate(reader):\n",
        "            try:\n",
        "                data.append(row)\n",
        "            except csv.Error as e:\n",
        "                print(f\"Error reading row {i}: {e}\")\n",
        "    return pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "# Load data with error handling\n",
        "data = load_csv_with_error_handling(\"all_sources_metadata_2020-03-13.csv\")\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz7puDNer4DZ",
        "outputId": "2996b91f-850b-4e2e-e1c4-5cb56d4c1b9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        sha source_x  \\\n",
            "0  c630ebcdf30652f0422c3ec12a00b50241dc9bd9      CZI   \n",
            "1  53eccda7977a31e3d0f565c884da036b1e85438e      CZI   \n",
            "2  210a892deb1c61577f6fba58505fd65356ce6636      CZI   \n",
            "3  e3b40cc8e0e137c416b4a2273a4dca94ae8178cc      CZI   \n",
            "4  92c2c9839304b4f2bc1276d41b1aa885d8b364fd      CZI   \n",
            "\n",
            "                                               title  \\\n",
            "0  Angiotensin-converting enzyme 2 (ACE2) as a SA...   \n",
            "1  Comparative genetic analysis of the novel coro...   \n",
            "2  Incubation Period and Other Epidemiological Ch...   \n",
            "3  Characteristics of and Public Health Responses...   \n",
            "4       Imaging changes in severe COVID-19 pneumonia   \n",
            "\n",
            "                          doi pmcid pubmed_id   license  \\\n",
            "0  10.1007/s00134-020-05985-9        32125455  cc-by-nc   \n",
            "1   10.1038/s41421-020-0147-1                     cc-by   \n",
            "2          10.3390/jcm9020538                     cc-by   \n",
            "3          10.3390/jcm9020575        32093211     cc-by   \n",
            "4  10.1007/s00134-020-05976-w        32125453  cc-by-nc   \n",
            "\n",
            "                                            abstract publish_time  \\\n",
            "0                                                            2020   \n",
            "1                                                            2020   \n",
            "2  The geographic spread of 2019 novel coronaviru...         2020   \n",
            "3  In December 2019, cases of unidentified pneumo...         2020   \n",
            "4                                                            2020   \n",
            "\n",
            "                                             authors  \\\n",
            "0  Zhang, Haibo; Penninger, Josef M.; Li, Yimin; ...   \n",
            "1  Cao, Yanan; Li, Lin; Feng, Zhimin; Wan, Shengq...   \n",
            "2  Linton, M. Natalie; Kobayashi, Tetsuro; Yang, ...   \n",
            "3                   Deng, Sheng-Qun; Peng, Hong-Juan   \n",
            "4                                         Zhang, Wei   \n",
            "\n",
            "                        journal Microsoft Academic Paper ID WHO #Covidence  \\\n",
            "0            Intensive Care Med                  2002765492          #3252   \n",
            "1                Cell Discovery                  3003430844          #1861   \n",
            "2  Journal of Clinical Medicine                  3006065484          #1043   \n",
            "3                    J Clin Med                   177663115          #1999   \n",
            "4            Intensive Care Med                  3006643024          #3242   \n",
            "\n",
            "  has_full_text  \n",
            "0          True  \n",
            "1          True  \n",
            "2          True  \n",
            "3          True  \n",
            "4         False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import preprocess_string, remove_stopwords, strip_numeric, strip_punctuation, strip_multiple_whitespaces\n",
        "from gensim.utils import simple_preprocess\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "6mQspgz-r7-X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "data.dropna(subset=['title'], inplace=True)\n",
        "data.drop_duplicates(subset=['title'], inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "fylGonWXsDnH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.parsing.preprocessing import preprocess_string, strip_multiple_whitespaces, strip_punctuation, strip_numeric, remove_stopwords\n",
        "\n",
        "# Text Preprocessing using Gensim\n",
        "def custom_preprocess(text):\n",
        "    CUSTOM_FILTERS = [lambda x: x.lower(), strip_multiple_whitespaces, strip_punctuation, strip_numeric, remove_stopwords]\n",
        "    return preprocess_string(text, CUSTOM_FILTERS)\n",
        "\n",
        "data['processed_title'] = data['title'].apply(custom_preprocess)\n"
      ],
      "metadata": {
        "id": "3kI1rcv2sGHq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "def stem_text(text):\n",
        "    return ' '.join([stemmer.stem(word) for word in text])\n",
        "\n",
        "data['stemmed_title'] = data['processed_title'].apply(stem_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zdgkf0EsKgn",
        "outputId": "2c205def-1980-4043-f410-8aa9bb5d2126"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display final preprocessed dataset\n",
        "print(data[['title', 'processed_title', 'stemmed_title']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWreHnEbsNWv",
        "outputId": "763d850d-410b-4539-a700-007586cac8d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0  Angiotensin-converting enzyme 2 (ACE2) as a SA...   \n",
            "1  Comparative genetic analysis of the novel coro...   \n",
            "2  Incubation Period and Other Epidemiological Ch...   \n",
            "3  Characteristics of and Public Health Responses...   \n",
            "4       Imaging changes in severe COVID-19 pneumonia   \n",
            "\n",
            "                                     processed_title  \\\n",
            "0  [angiotensin, converting, enzyme, ace, sars, c...   \n",
            "1  [comparative, genetic, analysis, novel, corona...   \n",
            "2  [incubation, period, epidemiological, characte...   \n",
            "3  [characteristics, public, health, responses, c...   \n",
            "4       [imaging, changes, severe, covid, pneumonia]   \n",
            "\n",
            "                                       stemmed_title  \n",
            "0  angiotensin convert enzym ace sar cov receptor...  \n",
            "1  compar genet analysi novel coronaviru ncov sar...  \n",
            "2  incub period epidemiolog characterist novel co...  \n",
            "3  characterist public health respons coronaviru ...  \n",
            "4                   imag chang sever covid pneumonia  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoeOH7F6sQGn",
        "outputId": "e4ab960c-347e-446d-e796-af15ac332e48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                        sha source_x  \\\n",
            "0  c630ebcdf30652f0422c3ec12a00b50241dc9bd9      CZI   \n",
            "1  53eccda7977a31e3d0f565c884da036b1e85438e      CZI   \n",
            "2  210a892deb1c61577f6fba58505fd65356ce6636      CZI   \n",
            "3  e3b40cc8e0e137c416b4a2273a4dca94ae8178cc      CZI   \n",
            "4  92c2c9839304b4f2bc1276d41b1aa885d8b364fd      CZI   \n",
            "\n",
            "                                               title  \\\n",
            "0  Angiotensin-converting enzyme 2 (ACE2) as a SA...   \n",
            "1  Comparative genetic analysis of the novel coro...   \n",
            "2  Incubation Period and Other Epidemiological Ch...   \n",
            "3  Characteristics of and Public Health Responses...   \n",
            "4       Imaging changes in severe COVID-19 pneumonia   \n",
            "\n",
            "                          doi pmcid pubmed_id   license  \\\n",
            "0  10.1007/s00134-020-05985-9        32125455  cc-by-nc   \n",
            "1   10.1038/s41421-020-0147-1                     cc-by   \n",
            "2          10.3390/jcm9020538                     cc-by   \n",
            "3          10.3390/jcm9020575        32093211     cc-by   \n",
            "4  10.1007/s00134-020-05976-w        32125453  cc-by-nc   \n",
            "\n",
            "                                            abstract publish_time  \\\n",
            "0                                                            2020   \n",
            "1                                                            2020   \n",
            "2  The geographic spread of 2019 novel coronaviru...         2020   \n",
            "3  In December 2019, cases of unidentified pneumo...         2020   \n",
            "4                                                            2020   \n",
            "\n",
            "                                             authors  \\\n",
            "0  Zhang, Haibo; Penninger, Josef M.; Li, Yimin; ...   \n",
            "1  Cao, Yanan; Li, Lin; Feng, Zhimin; Wan, Shengq...   \n",
            "2  Linton, M. Natalie; Kobayashi, Tetsuro; Yang, ...   \n",
            "3                   Deng, Sheng-Qun; Peng, Hong-Juan   \n",
            "4                                         Zhang, Wei   \n",
            "\n",
            "                        journal Microsoft Academic Paper ID WHO #Covidence  \\\n",
            "0            Intensive Care Med                  2002765492          #3252   \n",
            "1                Cell Discovery                  3003430844          #1861   \n",
            "2  Journal of Clinical Medicine                  3006065484          #1043   \n",
            "3                    J Clin Med                   177663115          #1999   \n",
            "4            Intensive Care Med                  3006643024          #3242   \n",
            "\n",
            "  has_full_text                                    processed_title  \\\n",
            "0          True  [angiotensin, converting, enzyme, ace, sars, c...   \n",
            "1          True  [comparative, genetic, analysis, novel, corona...   \n",
            "2          True  [incubation, period, epidemiological, characte...   \n",
            "3          True  [characteristics, public, health, responses, c...   \n",
            "4         False       [imaging, changes, severe, covid, pneumonia]   \n",
            "\n",
            "                                       stemmed_title  \n",
            "0  angiotensin convert enzym ace sar cov receptor...  \n",
            "1  compar genet analysi novel coronaviru ncov sar...  \n",
            "2  incub period epidemiolog characterist novel co...  \n",
            "3  characterist public health respons coronaviru ...  \n",
            "4                   imag chang sever covid pneumonia  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### feature extraction\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# Feature Extraction\n",
        "vec2word_vectorizer = CountVectorizer(analyzer='word', max_df=0.95, min_df=2, stop_words='english')\n",
        "tfidf_vectorizer = TfidfVectorizer(analyzer='word', max_df=0.95, min_df=2, stop_words='english')\n",
        "\n",
        "vec2word_features = vec2word_vectorizer.fit_transform(data['stemmed_title'])\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(data['stemmed_title'])\n"
      ],
      "metadata": {
        "id": "TxJj6shmsTB_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### LDA\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Topic Modeling - LDA\n",
        "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
        "lda_vec2word = lda.fit_transform(vec2word_features)\n",
        "lda_tfidf = lda.fit_transform(tfidf_features)\n"
      ],
      "metadata": {
        "id": "znAuulTksYzX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### DIMENSIONALITY REDUCTION\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "lda_vec2word_pca = pca.fit_transform(lda_vec2word)\n",
        "lda_tfidf_pca = pca.fit_transform(lda_tfidf)\n"
      ],
      "metadata": {
        "id": "Njh11WG8sbXS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kivTZBRDskkK",
        "outputId": "16d4d472-8374-4838-dbc4-eccf4d845937"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1852, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_optimal_clusters(data, max_k):\n",
        "    inertias = []\n",
        "    for k in range(1, max_k+1):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        kmeans.fit(data)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "    return inertias\n"
      ],
      "metadata": {
        "id": "xqga8ovPtRjn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Convert sparse matrix to dense numpy array\n",
        "vec2word_features_dense = vec2word_features.toarray()\n",
        "tfidf_features_dense = tfidf_features.toarray()\n",
        "\n",
        "# Elbow Method for CountVectorizer\n",
        "max_k = 10\n",
        "vec2word_inertias = find_optimal_clusters(vec2word_features_dense, max_k)\n",
        "\n",
        "# Elbow Method for TfidfVectorizer\n",
        "tfidf_inertias = find_optimal_clusters(tfidf_features_dense, max_k)\n",
        "\n",
        "# Plotting the Elbow Method for CountVectorizer\n",
        "plt.plot(range(1, max_k+1), vec2word_inertias, marker='o')\n",
        "plt.title('Elbow Method for CountVectorizer')\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()\n",
        "\n",
        "# Plotting the Elbow Method for TfidfVectorizer\n",
        "plt.plot(range(1, max_k+1), tfidf_inertias, marker='o')\n",
        "plt.title('Elbow Method for TfidfVectorizer')\n",
        "plt.xlabel('Number of clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.show()\n",
        "\n",
        "# Apply clustering algorithms with optimal k\n",
        "optimal_k_vec2word = np.argmin(vec2word_inertias) + 1\n",
        "optimal_k_tfidf = np.argmin(tfidf_inertias) + 1\n",
        "\n",
        "kmeans_vec2word = KMeans(n_clusters=optimal_k_vec2word, random_state=42).fit_predict(vec2word_features_dense)\n",
        "kmeans_tfidf = KMeans(n_clusters=optimal_k_tfidf, random_state=42).fit_predict(tfidf_features_dense)\n",
        "\n",
        "# Agglomerative Clustering\n",
        "agglomerative = AgglomerativeClustering(n_clusters=optimal_k_vec2word).fit_predict(vec2word_features_dense)\n",
        "\n",
        "# DBSCAN\n",
        "dbscan = DBSCAN().fit_predict(vec2word_features_dense)  # Using DBSCAN as an example, you can choose another algorithm\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCIe0NrHsoMP",
        "outputId": "8cb512d4-92a8-4a49-f9c5-1b495abcc0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate silhouette score for KMeans with CountVectorizer\n",
        "silhouette_kmeans_vec2word = silhouette_score(vec2word_features_dense, kmeans_vec2word)\n",
        "print(\"Silhouette Score (KMeans with CountVectorizer):\", silhouette_kmeans_vec2word)\n",
        "\n",
        "# Calculate silhouette score for KMeans with TfidfVectorizer\n",
        "silhouette_kmeans_tfidf = silhouette_score(tfidf_features_dense, kmeans_tfidf)\n",
        "print(\"Silhouette Score (KMeans with TfidfVectorizer):\", silhouette_kmeans_tfidf)\n",
        "\n",
        "# Calculate silhouette score for Agglomerative Clustering with CountVectorizer\n",
        "silhouette_agglomerative = silhouette_score(vec2word_features_dense, agglomerative)\n",
        "print(\"Silhouette Score (Agglomerative Clustering with CountVectorizer):\", silhouette_agglomerative)\n",
        "\n",
        "# Check if dbscan resulted in more than one cluster\n",
        "if len(np.unique(dbscan)) > 1:\n",
        "    # Calculate silhouette score for DBSCAN with CountVectorizer\n",
        "    silhouette_dbscan = silhouette_score(vec2word_features_dense, dbscan)\n",
        "    print(\"Silhouette Score (DBSCAN with CountVectorizer):\", silhouette_dbscan)\n",
        "else:\n",
        "    silhouette_dbscan = None\n",
        "    print(\"DBSCAN did not result in more than one cluster.\")\n",
        "\n",
        "# Visualize clusters using silhouette plots\n",
        "def plot_silhouette(X, cluster_labels):\n",
        "    silhouette_vals = silhouette_samples(X, cluster_labels)\n",
        "    num_clusters = len(np.unique(cluster_labels))\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_xlim([-0.1, 1])\n",
        "    ax.set_ylim([0, len(X) + (num_clusters + 1) * 10])\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(num_clusters):\n",
        "        ith_cluster_silhouette_vals = silhouette_vals[cluster_labels == i]\n",
        "        ith_cluster_silhouette_vals.sort()\n",
        "        size_cluster_i = ith_cluster_silhouette_vals.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "        color = plt.cm.get_cmap(\"Spectral\")(i / num_clusters)\n",
        "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_vals, facecolor=color, edgecolor=color, alpha=0.7)\n",
        "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "        y_lower = y_upper + 10\n",
        "\n",
        "    ax.set_title(\"Silhouette Plot\")\n",
        "    ax.set_xlabel(\"Silhouette Coefficient Values\")\n",
        "    ax.set_ylabel(\"Cluster Label\")\n",
        "\n",
        "# Plot silhouette plot for KMeans with CountVectorizer\n",
        "plot_silhouette(vec2word_features_dense, kmeans_vec2word)\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xn3-L2cQxW85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sparse matrix to dense numpy array\n",
        "vec2word_features_dense = vec2word_features.toarray()\n",
        "\n",
        "# Davies-Bouldin Index\n",
        "dbi_kmeans_vec2word = davies_bouldin_score(vec2word_features_dense, kmeans_vec2word)\n",
        "dbi_agglomerative = davies_bouldin_score(vec2word_features_dense, agglomerative)\n",
        "\n",
        "print(\"Davies-Bouldin Index (KMeans with CountVectorizer):\", dbi_kmeans_vec2word)\n",
        "print(\"Davies-Bouldin Index (Agglomerative Clustering with CountVectorizer):\", dbi_agglomerative)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1BHs6Pi6NzuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define a function to assign cluster labels to data points and save it to a CSV file\n",
        "def assign_clusters_and_save(data, cluster_labels, output_file):\n",
        "    data_with_clusters = data.copy()\n",
        "    data_with_clusters['Cluster_Label'] = cluster_labels\n",
        "    data_with_clusters.to_csv(output_file, index=False)\n",
        "    print(\"Data with cluster labels saved to:\", output_file)\n",
        "\n",
        "# Usage example\n",
        "# data: Your original DataFrame\n",
        "# cluster_labels: Labels assigned by clustering algorithm\n",
        "# output_file: Path to save the CSV file\n",
        "assign_clusters_and_save(data, kmeans_vec2word, \"data_with_cluster_labels.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXtpdmsv4fyL",
        "outputId": "782d4374-253b-4754-f547-596d19a5fcd6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with cluster labels saved to: data_with_cluster_labels.csv\n"
          ]
        }
      ]
    }
  ]
}